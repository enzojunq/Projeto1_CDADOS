{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Enzo Junqueira\n",
    "\n",
    "Nome: Thomas Rudge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\Enzo\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Documentos\\INSPER\\2023\\2-SEMESTRE\\CIENCIA-DOS-DADOS\\Projeto 1\\Projeto1_CDADOS\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target: Avaliaremos quais reviews estao relacionados à utilização do Kindle, conteúdo do livro ou com erros de edição do livro (1 = Conteúdo, 2 = Amazon , 3 = Edição)</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comprei o livro e ele não baixou. Gostaria de ...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rótulos de Linha</td>\n",
       "      <td>Contagem de Mensagem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muita enrolação, pouca informação. A autora fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Não gostei, a capa diz mais do que o conteúdo ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Estava tentando há dias continuar lendo sem qu...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Incapaz de conviver com ideias diferentes na a...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Total Geral</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  \\\n",
       "0  Comprei o livro e ele não baixou. Gostaria de ...   \n",
       "1  Muita enrolação, pouca informação. A autora fi...   \n",
       "2  Não gostei, a capa diz mais do que o conteúdo ...   \n",
       "3  Estava tentando há dias continuar lendo sem qu...   \n",
       "4  Incapaz de conviver com ideias diferentes na a...   \n",
       "\n",
       "   Target: Avaliaremos quais reviews estao relacionados à utilização do Kindle, conteúdo do livro ou com erros de edição do livro (1 = Conteúdo, 2 = Amazon , 3 = Edição)  \\\n",
       "0                                                  2                                                                                                                        \n",
       "1                                                  1                                                                                                                        \n",
       "2                                                  1                                                                                                                        \n",
       "3                                                  1                                                                                                                        \n",
       "4                                                  1                                                                                                                        \n",
       "\n",
       "   Unnamed: 2        Unnamed: 3            Unnamed: 4  \n",
       "0         NaN  Rótulos de Linha  Contagem de Mensagem  \n",
       "1         NaN                 1                   190  \n",
       "2         NaN                 2                    72  \n",
       "3         NaN                 3                    38  \n",
       "4         NaN       Total Geral                   300  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino = pd.read_excel('dados_treino.xlsx')\n",
    "treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mensagem</th>\n",
       "      <th>Target: Avaliaremos quais reviews estao relacionados à utilização do Kindle, conteúdo do livro ou com erros de edição do livro (1 = Conteúdo, 2 = Amazon , 3 = Edição)</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Como o livro se concentra na política american...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rótulos de Linha</td>\n",
       "      <td>Contagem de Mensagem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boa estória. Quis ler antes de ver o filme, qu...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Não gostei. O livro o tempo todo traz narrativ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Muito confuso.</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comprei o livro logo após comprar \"Garota Exem...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(vazio)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Mensagem  \\\n",
       "0  Como o livro se concentra na política american...   \n",
       "1  Boa estória. Quis ler antes de ver o filme, qu...   \n",
       "2  Não gostei. O livro o tempo todo traz narrativ...   \n",
       "3                                     Muito confuso.   \n",
       "4  Comprei o livro logo após comprar \"Garota Exem...   \n",
       "\n",
       "   Target: Avaliaremos quais reviews estao relacionados à utilização do Kindle, conteúdo do livro ou com erros de edição do livro (1 = Conteúdo, 2 = Amazon , 3 = Edição)  \\\n",
       "0                                                  1                                                                                                                        \n",
       "1                                                  3                                                                                                                        \n",
       "2                                                  1                                                                                                                        \n",
       "3                                                  1                                                                                                                        \n",
       "4                                                  1                                                                                                                        \n",
       "\n",
       "   Unnamed: 2        Unnamed: 3            Unnamed: 4  \n",
       "0         NaN  Rótulos de Linha  Contagem de Mensagem  \n",
       "1         NaN                 1                   131  \n",
       "2         NaN                 2                    53  \n",
       "3         NaN                 3                    16  \n",
       "4         NaN           (vazio)                   NaN  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = pd.read_excel('dados_teste.xlsx')\n",
    "teste.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renomearemos a coluna de rótulos para algo mais simples, como \"Target\".\n",
    "Descartaremos as colunas desnecessárias.\n",
    "Carregaremos a lista de stop words do arquivo fornecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino.columns = ['Mensagem', 'Target', 'Drop1', 'Drop2', 'Drop3']\n",
    "teste.columns = ['Mensagem', 'Target', 'Drop1', 'Drop2', 'Drop3']\n",
    "\n",
    "treino = treino[['Mensagem', 'Target']]\n",
    "teste = teste[['Mensagem', 'Target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "with open('stopwords.txt', 'r') as file:\n",
    "    stopwords = file.read().splitlines()\n",
    "\n",
    "stopwords = [unidecode(word.lower()) for word in stopwords]\n",
    "\n",
    "# Splitting the single string in the stopwords_list into individual words\n",
    "stopwords = stopwords[0].split(', ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpar as mensagens, removendo caracteres especiais, números e pontuações.\n",
    "Converter todas as palavras para minúsculas para manter a uniformidade.\n",
    "Remover as stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                            Mensagem  Target\n",
       " 0  comprei baixou gostaria saber vai baixar quero...       2\n",
       " 1  enrolacao informacao autora fica contando vida...       1\n",
       " 2                          gostei capa mais conteudo       1\n",
       " 3  tentando dias continuar lendo ficasse sono inc...       1\n",
       " 4  incapaz conviver ideias diferentes academia br...       1,\n",
       "                                             Mensagem  Target\n",
       " 0  concentra politica americana duas decadas espe...       1\n",
       " 1  boa estoria quis ler filme epoca fez sucesso e...       3\n",
       " 2  gostei tempo traz narrativas cenarios eua bols...       1\n",
       " 3                                            confuso       1\n",
       " 4  comprei logo comprar garota exemplar sair qual...       1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "def limpa_texto(text, stopwords):\n",
    "    \n",
    "     # Remove acentos e caracteres especiais usando unidecode\n",
    "    novo_texto = unidecode(text)\n",
    "\n",
    "   \n",
    "    # Remove todos os caracteres que não são letras ou números\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', novo_texto)\n",
    "\n",
    "    text = cleaned_text.lower()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "# Aplica a função limpa_texto para todas as mensagens\n",
    "treino['Mensagem'] = treino['Mensagem'].apply(lambda x: limpa_texto(x, stopwords))\n",
    "teste['Mensagem'] = teste['Mensagem'].apply(lambda x: limpa_texto(x, stopwords))\n",
    "\n",
    "\n",
    "treino.head(), teste.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target: Avaliaremos quais reviews estão relacionados à utilização do Kindle, conteúdo do livro ou com erros de edição do livro\n",
    "\n",
    "1. Kindle: Reviews relacionados à experiência de leitura no dispositivo Kindle.\n",
    "2. Conteúdo: Reviews que discutem o conteúdo do livro, como enredo, personagens, estilo de escrita, etc.\n",
    "3. Erros de Edição: Reviews que mencionam erros de edição, como problemas de formatação, erros de impressão...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calcular as probabilidades a priori para cada classe (a frequência de cada classe nos dados de treinamento).\n",
    "2. Calcular as probabilidades condicionais de cada palavra dada a classe (a frequência de cada palavra em cada classe nos dados de treinamento).\n",
    "3. Aplicar a suavização de Laplace para lidar com palavras não vistas nos dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.633333\n",
       "2    0.240000\n",
       "3    0.126667\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula a probabilidade de cada classe\n",
    "prob = treino['Target'].value_counts(normalize=True)\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As probabilidades a priori para cada classe (Target) são as seguintes:\n",
    "\n",
    "1. Conteúdo: 63.33%\n",
    "2. Kindle: 24.00%\n",
    "3. Erros de Edição: 12.67%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conteúdo\n",
    "conteudo = treino[treino.Target == 1]\n",
    "# conteudo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kindle\n",
    "kindle = treino[treino.Target == 2]\n",
    "# kindle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edição\n",
    "edicao = treino[treino.Target == 3]\n",
    "# edicao.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('mais', 85), ('ler', 47), ('historia', 46), ('ser', 44), ('autor', 43)],\n",
       " [('amazon', 34),\n",
       "  ('mais', 32),\n",
       "  ('preco', 25),\n",
       "  ('kindle', 22),\n",
       "  ('produto', 21)],\n",
       " [('mais', 16), ('veio', 15), ('box', 15), ('paginas', 14), ('produto', 10)])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Defining a function to count words in a DataFrame\n",
    "def count_words(df):\n",
    "    # Concatenating all the messages and splitting into words\n",
    "    words = ' '.join(df['Mensagem']).split()\n",
    "    # Counting the frequency of each word\n",
    "    word_count = Counter(words)\n",
    "    return word_count\n",
    "\n",
    "# Counting the words in each subcategory\n",
    "conteudo_word_count = count_words(conteudo)\n",
    "kindle_word_count = count_words(kindle)\n",
    "edicao_word_count = count_words(edicao)\n",
    "\n",
    "total_word_count = conteudo_word_count + kindle_word_count + edicao_word_count\n",
    "\n",
    "\n",
    "\n",
    "# Displaying the most common words in each subcategory\n",
    "conteudo_word_count.most_common(5), kindle_word_count.most_common(5), edicao_word_count.most_common(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade de estar em conteudo:  0.6333333333333333\n",
      "Probabilidade de estar em kindle:  0.24\n",
      "Probabilidade de estar em edicao:  0.12666666666666668\n",
      "Total de palavras em conteudo:  4970\n",
      "Total de palavras em kindle:  1859\n",
      "Total de palavras em edicao:  918\n",
      "Total de palavras unicas:  3380\n"
     ]
    }
   ],
   "source": [
    "# Calculating the prior probabilities for each category\n",
    "prior_prob_conteudo = len(conteudo) / len(treino)\n",
    "prior_prob_kindle = len(kindle) / len(treino)\n",
    "prior_prob_edicao = len(edicao) / len(treino)\n",
    "\n",
    "# Calculating the total number of words in each subcategory\n",
    "total_words_conteudo = sum(conteudo_word_count.values())\n",
    "total_words_kindle = sum(kindle_word_count.values())\n",
    "total_words_edicao = sum(edicao_word_count.values())\n",
    "\n",
    "# Calculating the total number of unique words in the entire training set\n",
    "total_unique_words = len(set(total_word_count.keys()))\n",
    "\n",
    "# Displaying the prior probabilities and total number of words\n",
    "prior_prob_conteudo, prior_prob_kindle, prior_prob_edicao, total_words_conteudo, total_words_kindle, total_words_edicao, total_unique_words\n",
    "\n",
    "print('Probabilidade de estar em conteudo: ', prior_prob_conteudo)\n",
    "print('Probabilidade de estar em kindle: ', prior_prob_kindle)\n",
    "print('Probabilidade de estar em edicao: ', prior_prob_edicao)\n",
    "print('Total de palavras em conteudo: ', total_words_conteudo)\n",
    "print('Total de palavras em kindle: ', total_words_kindle)\n",
    "print('Total de palavras em edicao: ', total_words_edicao)\n",
    "print('Total de palavras unicas: ', total_unique_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enrolacao', 0.00047904191616766467),\n",
       " ('informacao', 0.00023952095808383233),\n",
       " ('autora', 0.0019161676646706587),\n",
       " ('fica', 0.0008383233532934132),\n",
       " ('contando', 0.00023952095808383233)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_conditional_probabilities(word_count, total_words, total_unique_words):\n",
    "    # Suavização de Laplace\n",
    "    probabilities = {}\n",
    "    for word, count in word_count.items():\n",
    "        probabilities[word] = (count + 1) / (total_words + total_unique_words)\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "# Calculating the conditional probabilities for each word given the category\n",
    "prob_conteudo = calculate_conditional_probabilities(conteudo_word_count, total_words_conteudo, total_unique_words)\n",
    "prob_kindle = calculate_conditional_probabilities(kindle_word_count, total_words_kindle, total_unique_words)\n",
    "prob_edicao = calculate_conditional_probabilities(edicao_word_count, total_words_edicao, total_unique_words)\n",
    "\n",
    "# Displaying the conditional probabilities of the first few words in the 'conteudo' category\n",
    "list(prob_conteudo.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por que não usar o próprio classificador para gerar mais amostras de treinamento?\n",
    "Usar o próprio classificador para gerar mais amostras de treinamento pode levar a problemas de viés e superajuste (overfitting). O modelo já foi treinado com o conjunto de dados existente e tem suas limitações e viéses baseados nesse conjunto de dados. Adicionar mais amostras geradas pelo próprio modelo só reforçará os viéses e limitações existentes, e não contribuirá para a generalização do modelo para dados não vistos. Além disso, pode levar a uma falsa sensação de precisão e confiança no modelo, já que as amostras adicionadas são, por definição, bem classificadas pelo modelo.\n",
    "\n",
    "### Diferentes cenários para Naïve Bayes\n",
    "1. Diagnóstico Médico:\n",
    "O classificador Naïve Bayes pode ser usado para diagnosticar doenças com base em sintomas. Cada sintoma pode ser tratado como uma característica, e o Naïve Bayes pode ser usado para calcular a probabilidade de uma doença específica dado um conjunto de sintomas.\n",
    "\n",
    "2. Análise de Sentimento em Redes Sociais:\n",
    "O Naïve Bayes pode ser empregado para analisar o sentimento de usuários em redes sociais, classificando postagens ou comentários como positivos, negativos ou neutros. Isso pode ser útil para empresas monitorarem a opinião pública sobre seus produtos ou serviços e ajustarem suas estratégias de marketing e comunicação conforme necessário.\n",
    "\n",
    "### Sugestões de Melhorias e Como Implementar:\n",
    "1. Limpeza e Pré-processamento Avançado:\n",
    "Como Implementar: Utilizar técnicas mais avançadas de processamento de linguagem natural, como a lematização, para reduzir as palavras à sua forma base e remover variações.\n",
    "Referências: Bibliotecas como NLTK e SpaCy em Python oferecem ferramentas avançadas de pré-processamento de texto.\n",
    "Link: https://codewithgolu.com/python/a-comprehensive-guide-to-text-preprocessing-with-nltk-and-spa-cy/\n",
    "\n",
    "2. Balanceamento de Classes:\n",
    "Como Implementar: Utilizar técnicas de reamostragem como oversampling ou undersampling para equilibrar a distribuição das classes no conjunto de treinamento.\n",
    "Referências: A biblioteca imbalanced-learn em Python oferece métodos para lidar com conjuntos de dados desbalanceados. Link: https://www.analyticsvidhya.com/blog/2022/05/handling-imbalanced-data-with-imbalance-learn-in-python/\n",
    "\n",
    "3. Otimização de Hiperparâmetros:\n",
    "Como Implementar: Utilizar técnicas de otimização de hiperparâmetros, como busca em grade (Grid Search), para encontrar os melhores parâmetros para o modelo.\n",
    "Referências: A biblioteca Scikit-learn em Python oferece métodos como GridSearchCV para otimização de hiperparâmetros. Link: https://pyimagesearch.com/2021/05/24/grid-search-hyperparameter-tuning-with-scikit-learn-gridsearchcv/\n",
    "\n",
    "4. Seleção de Características:\n",
    "Como Implementar: Empregar técnicas de seleção de características para identificar e manter apenas as características mais informativas e remover características redundantes ou irrelevantes.\n",
    "Referências: Métodos como o teste do qui-quadrado (chi-squared test) podem ser usados para avaliar a importância das características.\n",
    "\n",
    "5. Uso de Modelos Mais Complexos:\n",
    "Como Implementar: Experimentar modelos mais avançados e complexos como Máquinas de Vetores de Suporte (SVM) ou Redes Neurais.\n",
    "Referências: Frameworks como TensorFlow e PyTorch permitem a implementação de modelos mais avançados de aprendizado de máquina.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CONSIDEROU mais de duas categorias na variável Target e INCREMENTOU a quantidade de notícias, mantendo pelo menos 250 notícias por categoria (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* Para Target com duas categorias: CRIOU pelo menos quatro categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item Qualidade do Classificador a partir de novas separações das Notícias entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
